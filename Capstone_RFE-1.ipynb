{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
       "       'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount',\n",
       "       'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'HourlyRate',\n",
       "       'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction',\n",
       "       'MaritalStatus', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
       "       'Over18', 'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
       "       'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n",
       "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
       "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
       "       'YearsWithCurrManager'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "#df=df.drop(['EmployeeNumber','EmployeeCount','StandardHours','Over18'],axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binning\n",
    "df['MonthlyIncome']=pd.cut(df['MonthlyIncome'],bins=4,labels=['Very low','Low','Moderate','High'])\n",
    "#Binning\n",
    "df['Age']=pd.cut(df['Age'],bins=3,labels=['Youth','Middle Aged','Elderly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Attrition', 'BusinessTravel', 'Department', 'EducationField',\n",
       "       'Gender', 'JobRole', 'MaritalStatus', 'MonthlyIncome', 'Over18',\n",
       "       'OverTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num=df.select_dtypes(include=['int64','float'])\n",
    "df_cat=df.select_dtypes(exclude=['int64','float'])\n",
    "df_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df_cat['MonthlyIncome']=le.fit_transform(df['MonthlyIncome'])\n",
    "df_cat['Age']=le.fit_transform(df['Age'])\n",
    "df_cat['BusinessTravel']=le.fit_transform(df['BusinessTravel'])\n",
    "df_cat['Department']=le.fit_transform(df['Department'])\n",
    "df_cat['EducationField']=le.fit_transform(df['EducationField'])\n",
    "df_cat['Gender']=le.fit_transform(df['Gender'])\n",
    "df_cat['JobRole']=le.fit_transform(df['JobRole'])\n",
    "df_cat['MaritalStatus']=le.fit_transform(df['MaritalStatus'])\n",
    "df_cat['OverTime']=le.fit_transform(df['OverTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.concat([df_num,df_cat],axis=1)\n",
    "df1=df1.drop(['EmployeeCount','StandardHours','Over18'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>Gender</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>OverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1102</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19479</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24907</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2396</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1392</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23159</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16632</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DailyRate  DistanceFromHome  Education  EmployeeNumber  \\\n",
       "0       1102                 1          2               1   \n",
       "1        279                 8          1               2   \n",
       "2       1373                 2          2               4   \n",
       "3       1392                 3          4               5   \n",
       "4        591                 2          1               7   \n",
       "\n",
       "   EnvironmentSatisfaction  HourlyRate  JobInvolvement  JobLevel  \\\n",
       "0                        2          94               3         2   \n",
       "1                        3          61               2         2   \n",
       "2                        4          92               2         1   \n",
       "3                        4          56               3         1   \n",
       "4                        1          40               3         1   \n",
       "\n",
       "   JobSatisfaction  MonthlyRate  ...  Age  Attrition  BusinessTravel  \\\n",
       "0                4        19479  ...    1        Yes               2   \n",
       "1                2        24907  ...    0         No               1   \n",
       "2                3         2396  ...    1        Yes               2   \n",
       "3                3        23159  ...    1         No               1   \n",
       "4                2        16632  ...    2         No               2   \n",
       "\n",
       "   Department  EducationField  Gender  JobRole  MaritalStatus  MonthlyIncome  \\\n",
       "0           2               1       0        7              2              1   \n",
       "1           1               1       1        6              1              3   \n",
       "2           1               4       1        2              2              3   \n",
       "3           1               1       0        6              1              3   \n",
       "4           1               3       1        2              1              3   \n",
       "\n",
       "   OverTime  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Attrition']=df1['Attrition'].replace({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Scale the input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x=df1.drop('Attrition',axis=1)\n",
    "y=df1['Attrition']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import r2_score\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature subset :  2\n",
      "R2 :  -0.20491803278688536\n",
      "feature subset :  3\n",
      "R2 :  -0.10852459016393445\n",
      "feature subset :  4\n",
      "R2 :  -0.07639344262295089\n",
      "feature subset :  5\n",
      "R2 :  -0.04426229508196733\n",
      "feature subset :  6\n",
      "R2 :  -0.04426229508196733\n",
      "feature subset :  7\n",
      "R2 :  -0.012131147540983767\n",
      "feature subset :  8\n",
      "R2 :  0.05213114754098347\n",
      "feature subset :  9\n",
      "R2 :  -0.028196721311475548\n",
      "feature subset :  10\n",
      "R2 :  0.019999999999999907\n",
      "feature subset :  11\n",
      "R2 :  0.003934426229508126\n",
      "feature subset :  12\n",
      "R2 :  0.003934426229508126\n"
     ]
    }
   ],
   "source": [
    "for i in [2,3,4,5,6,7,8,9,10,11,12]:\n",
    "    lr=LogisticRegression()\n",
    "    rfe_mod=RFE(estimator=lr,n_features_to_select=i)\n",
    "    rfe_feat_mod=rfe_mod.fit(xtrain,ytrain)\n",
    "    rank=rfe_feat_mod.ranking_\n",
    "    res=pd.DataFrame()\n",
    "    res['feature']=xtrain.columns\n",
    "    res['rank']=rank\n",
    "    col=res[res['rank']==1]['feature']\n",
    "    lr=LogisticRegression()\n",
    "    lr.fit(xtrain[col],ytrain)\n",
    "    ypred=lr.predict(xtest[col])\n",
    "    print('feature subset : ',i)\n",
    "    print('R2 : ',r2_score(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DistanceFromHome', 'EnvironmentSatisfaction', 'JobInvolvement',\n",
       "       'JobLevel', 'JobSatisfaction', 'NumCompaniesWorked',\n",
       "       'PercentSalaryHike', 'PerformanceRating',\n",
       "       'RelationshipSatisfaction', 'StockOptionLevel',\n",
       "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
       "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
       "       'YearsWithCurrManager', 'Age', 'BusinessTravel', 'Department',\n",
       "       'EducationField', 'Gender', 'MaritalStatus', 'MonthlyIncome',\n",
       "       'OverTime'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_mod=RFE(estimator=lr,n_features_to_select=25)\n",
    "rfe_feat_mod1=rfe_mod.fit(xtrain,ytrain)\n",
    "rank1=rfe_feat_mod1.ranking_\n",
    "res1=pd.DataFrame()\n",
    "res1['feature']=xtrain.columns\n",
    "res1['rank1']=rank1\n",
    "col=res1[res1['rank1']==1]['feature']\n",
    "col.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df1[['DistanceFromHome', 'EnvironmentSatisfaction', 'JobInvolvement',\n",
    "       'JobLevel', 'JobSatisfaction', 'NumCompaniesWorked',\n",
    "       'PercentSalaryHike', 'PerformanceRating',\n",
    "       'RelationshipSatisfaction', 'StockOptionLevel',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager', 'Age', 'BusinessTravel', 'Department',\n",
    "       'EducationField', 'Gender', 'MaritalStatus', 'MonthlyIncome',\n",
    "       'OverTime']]\n",
    "x_scaler=StandardScaler()\n",
    "x_std=x_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[360  10]\n",
      " [ 49  22]]\n",
      "\n",
      "Accuracy Train:  0.880466472303207\n",
      "Accuracy Test: 0.8662131519274376\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       370\n",
      "           1       0.69      0.31      0.43        71\n",
      "\n",
      "    accuracy                           0.87       441\n",
      "   macro avg       0.78      0.64      0.68       441\n",
      "weighted avg       0.85      0.87      0.84       441\n",
      "\n",
      "AUC Test:  0.7955843167110773\n",
      "True positives: 22\n",
      "True negatives: 360\n",
      "False positives (Type I error): 10\n",
      "False negatives (Type II error): 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR Scaled</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0   LR Scaled                 59            10             49      0.69   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.31           0.88          0.87     0.43     0.8  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report, roc_auc_score,roc_curve,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_std,y,test_size=0.3,random_state=3,stratify=y)\n",
    "\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "ytest_prob = lr.predict_proba(X_test)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,lr.predict(X_train)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"LR Scaled\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,lr.predict(X_train)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "LR_Scaled =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "LR_Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[360  10]\n",
      " [ 49  22]]\n",
      "\n",
      "Accuracy Train:  0.880466472303207\n",
      "Accuracy Test: 0.8662131519274376\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       370\n",
      "           1       0.69      0.31      0.43        71\n",
      "\n",
      "    accuracy                           0.87       441\n",
      "   macro avg       0.78      0.64      0.68       441\n",
      "weighted avg       0.85      0.87      0.84       441\n",
      "\n",
      "AUC Test:  0.7955843167110773\n",
      "True positives: 22\n",
      "True negatives: 360\n",
      "False positives (Type I error): 10\n",
      "False negatives (Type II error): 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR Scaled</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0   LR Scaled                 59            10             49      0.69   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.31           0.88          0.87     0.43     0.8  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report, roc_auc_score,roc_curve,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_std,y,test_size=0.3,random_state=3,stratify=y)\n",
    "\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "ytest_prob = lr.predict_proba(X_test)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,lr.predict(X_train)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"LR Scaled\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,lr.predict(X_train)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "LR_Scaled =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "LR_Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-28328cfe5551>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLR\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkf\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'roc_auc :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLR_Bag_be\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "LR=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "kf =KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "cv_results = cross_val_score(lr, X_train, y_train,cv=kf, scoring='roc_auc')\n",
    "print('roc_auc :',1-np.min(LR_Bag_be))\n",
    "print('Bias error :',np.min(LR_Bag_be))\n",
    "print('Variance error :',np.min(LR_Bag_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold,cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR_Bag_var=[]\n",
    "LR_Bag_be=[]\n",
    "for val in np.arange(1,100):\n",
    "  LR=LogisticRegression()\n",
    "  lr_Bag=BaggingClassifier(base_estimator=LR,n_estimators=val,random_state=0)\n",
    "  kf =KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "  cv_results = cross_val_score(lr_Bag, x_std, y,cv=kf, scoring='roc_auc')\n",
    "  LR_Bag_var.append(np.std(cv_results,ddof=1))\n",
    "  LR_Bag_be.append(np.mean(1-cv_results))\n",
    "  \n",
    "np.argmin(LR_Bag_var),np.argmin(LR_Bag_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ada_bias=[]\n",
    "for val in np.arange(1,100):\n",
    "  Ada=AdaBoostClassifier(base_estimator=lr,n_estimators=val,random_state=0)\n",
    "  kfold = KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "  cv_results = cross_val_score(Ada, x_std, y,cv=kfold, scoring='roc_auc')\n",
    "  Ada_bias.append(1-np.mean(cv_results))\n",
    "  \n",
    "print('roc_auc :',1-np.min(Ada_bias))\n",
    "print('Bias error :',np.min(Ada_bias))\n",
    "np.argmin(Ada_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GB_bias=[]\n",
    "GB_var=[]\n",
    "for val in np.arange(1,200):\n",
    "  gb=GradientBoostingClassifier(n_estimators=val,random_state=0)\n",
    "  kfold =KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "  cv_results = cross_val_score(gb, x_std, y,cv=kfold, scoring='roc_auc')\n",
    "  GB_bias.append(1-np.mean(cv_results))\n",
    "  GB_var.append(np.std(cv_results))\n",
    "  #print(val,1-np.mean(cv_results))\n",
    "\n",
    "    \n",
    "print('roc_auc :',1-np.min(GB_bias))\n",
    "print('Bias error :',np.min(GB_bias))\n",
    "print('Variance error :',np.min(GB_var))\n",
    "np.argmin(GB_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data leak\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.3)\n",
    "ss=StandardScaler()\n",
    "xtrains=ss.fit_transform(x_train)\n",
    "xtests=ss.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[364  16]\n",
      " [ 45  16]]\n",
      "\n",
      "Accuracy Train:  0.8746355685131195\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       380\n",
      "           1       0.50      0.26      0.34        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.69      0.61      0.63       441\n",
      "weighted avg       0.84      0.86      0.84       441\n",
      "\n",
      "AUC Test:  0.7602243313201035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve,accuracy_score\n",
    "lr1=LogisticRegression()\n",
    "lr1.fit(xtrains,y_train)\n",
    "y_pred = lr1.predict(xtests)\n",
    "ytest_prob = lr1.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,lr1.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[364  16]\n",
      " [ 45  16]]\n",
      "\n",
      "Accuracy Train:  0.8746355685131195\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       380\n",
      "           1       0.50      0.26      0.34        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.69      0.61      0.63       441\n",
      "weighted avg       0.84      0.86      0.84       441\n",
      "\n",
      "AUC Test:  0.7602243313201035\n",
      "True positives: 16\n",
      "True negatives: 364\n",
      "False positives (Type I error): 16\n",
      "False negatives (Type II error): 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag_LR</td>\n",
       "      <td>61</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0      Bag_LR                 61            16             45       0.5   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.26           0.77          0.86     0.34    0.76  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "Bag=BaggingClassifier(base_estimator=lr,n_estimators=9,random_state=0)\n",
    "Bag=LogisticRegression()\n",
    "Bag.fit(xtrains,y_train)\n",
    "y_pred = Bag.predict(xtests)\n",
    "ytest_prob = Bag.predict_proba(xtests)[:,1]\n",
    "    \n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,Bag.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"Bag_LR\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,Bag.predict(X_train)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "bag_LR =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "bag_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[376   4]\n",
      " [ 51  10]]\n",
      "\n",
      "Accuracy Train:  0.8688046647230321\n",
      "Accuracy Test: 0.8752834467120182\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       380\n",
      "           1       0.71      0.16      0.27        61\n",
      "\n",
      "    accuracy                           0.88       441\n",
      "   macro avg       0.80      0.58      0.60       441\n",
      "weighted avg       0.86      0.88      0.84       441\n",
      "\n",
      "AUC Test:  0.7557808455565143\n",
      "True positives: 10\n",
      "True negatives: 376\n",
      "False positives (Type I error): 4\n",
      "False negatives (Type II error): 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada_LR</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0      Ada_LR                 55             4             51      0.71   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.16            0.8          0.88     0.27    0.76  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "Ada=AdaBoostClassifier(base_estimator=lr,n_estimators=7,random_state=0)\n",
    "Ada.fit(X_train,y_train)\n",
    "Ada.fit(xtrains,y_train)\n",
    "y_pred = Ada.predict(xtests)\n",
    "ytest_prob = Ada.predict_proba(xtests)[:,1]\n",
    "    \n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,Ada.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"Ada_LR\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,Ada.predict(X_train)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "Ada_LR =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "Ada_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[365  15]\n",
      " [ 42  19]]\n",
      "\n",
      "Accuracy Train:  0.9630709426627794\n",
      "Accuracy Test: 0.8707482993197279\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       380\n",
      "           1       0.56      0.31      0.40        61\n",
      "\n",
      "    accuracy                           0.87       441\n",
      "   macro avg       0.73      0.64      0.66       441\n",
      "weighted avg       0.85      0.87      0.85       441\n",
      "\n",
      "AUC Test:  0.8059965487489217\n",
      "True positives: 19\n",
      "True negatives: 365\n",
      "False positives (Type I error): 15\n",
      "False negatives (Type II error): 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GB</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0          GB                 57            15             42      0.56   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.31           0.75          0.87      0.4    0.81  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "gb=GradientBoostingClassifier(n_estimators=108,random_state=0)\n",
    "gb.fit(xtrains,y_train)\n",
    "y_pred = gb.predict(xtests)\n",
    "ytest_prob = gb.predict_proba(xtests)[:,1]\n",
    "    \n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,gb.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"GB\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,gb.predict(X_train)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "GB =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[378   2]\n",
      " [ 54   7]]\n",
      "\n",
      "Accuracy Train:  0.8668610301263362\n",
      "Accuracy Test: 0.873015873015873\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       380\n",
      "           1       0.78      0.11      0.20        61\n",
      "\n",
      "    accuracy                           0.87       441\n",
      "   macro avg       0.83      0.55      0.57       441\n",
      "weighted avg       0.86      0.87      0.83       441\n",
      "\n",
      "AUC Test:  0.6344262295081968\n",
      "True positives: 7\n",
      "True negatives: 378\n",
      "False positives (Type I error): 2\n",
      "False negatives (Type II error): 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Scaled</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0  KNN Scaled                 56             2             54      0.78   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.11           0.87          0.87      0.2    0.63  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(xtrains,y_train)\n",
    "y_pred = knn.predict(xtests)\n",
    "ytest_prob = knn.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,knn.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"KNN Scaled\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train=round(accuracy_score(y_train,knn.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "Kneighbors =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "Kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 68, 'weights': 'distance'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "knn=KNeighborsClassifier()\n",
    "param={'n_neighbors':np.arange(1,70),'weights':['uniform','distance']}\n",
    "kf =KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "grid=GridSearchCV(knn,param,cv=kf,scoring='roc_auc')\n",
    "grid.fit(x_std,y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[380   0]\n",
      " [ 61   0]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       380\n",
      "           1       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.43      0.50      0.46       441\n",
      "weighted avg       0.74      0.86      0.80       441\n",
      "\n",
      "AUC Test:  0.737532355478861\n",
      "True positives: 0\n",
      "True negatives: 380\n",
      "False positives (Type I error): 0\n",
      "False negatives (Type II error): 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Scaled hypertuned</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Description Misclassifications Type I errors Type II errors  \\\n",
       "0  KNN Scaled hypertuned                 61             0             61   \n",
       "\n",
       "  Precision Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0       0.0    0.0            1.0          0.86      0.0    0.74  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Scale the input\n",
    "knn=KNeighborsClassifier(n_neighbors= 60, weights= 'distance')\n",
    "knn.fit(xtrains,y_train)\n",
    "y_pred = knn.predict(xtests)\n",
    "ytest_prob = knn.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,knn.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"KNN Scaled hypertuned\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train=accuracy_score(y_train,knn.predict(xtrains))\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "knn_tuned =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "knn_tuned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged KNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "knn_Bag_var=[]\n",
    "knn_Bag_be=[]\n",
    "for val in np.arange(1,100):\n",
    "  knn=KNeighborsClassifier(n_neighbors= 60, weights= 'distance')\n",
    "  knn_Bag=BaggingClassifier(base_estimator=knn,n_estimators=val,random_state=0)\n",
    "  kf =KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "  cv_results = cross_val_score(knn_Bag, x_std, y,cv=kf, scoring='roc_auc')\n",
    "  knn_Bag_var.append(np.std(cv_results,ddof=1))\n",
    "  knn_Bag_be.append(np.mean(1-cv_results))\n",
    "  \n",
    "np.argmin(knn_Bag_var),np.argmin(knn_Bag_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[380   0]\n",
      " [ 61   0]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       380\n",
      "           1       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.43      0.50      0.46       441\n",
      "weighted avg       0.74      0.86      0.80       441\n",
      "\n",
      "AUC Test:  0.746548748921484\n",
      "True positives: 0\n",
      "True negatives: 380\n",
      "False positives (Type I error): 0\n",
      "False negatives (Type II error): 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag_KNN</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0     Bag_KNN                 61             0             61       0.0   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0    0.0            0.8          0.86      0.0    0.75  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Bag=BaggingClassifier(base_estimator=knn,n_estimators=24,random_state=0)\n",
    "Bag.fit(xtrains,y_train)\n",
    "y_pred = Bag.predict(xtests)\n",
    "ytest_prob = Bag.predict_proba(xtests)[:,1]\n",
    "    \n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,Bag.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"Bag_KNN\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,Bag.predict(X_train)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "bag_KNN=pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "bag_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[304  76]\n",
      " [ 28  33]]\n",
      "\n",
      "Accuracy Train:  0.7803692905733722\n",
      "Accuracy Test: 0.764172335600907\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       380\n",
      "           1       0.30      0.54      0.39        61\n",
      "\n",
      "    accuracy                           0.76       441\n",
      "   macro avg       0.61      0.67      0.62       441\n",
      "weighted avg       0.83      0.76      0.79       441\n",
      "\n",
      "AUC Test:  0.711518550474547\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB=GaussianNB()\n",
    "NB.fit(xtrains,y_train)\n",
    "y_pred = NB.predict(xtests)\n",
    "ytest_prob = NB.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,NB.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[304  76]\n",
      " [ 28  33]]\n",
      "\n",
      "Accuracy Train:  0.7803692905733722\n",
      "Accuracy Test: 0.764172335600907\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       380\n",
      "           1       0.30      0.54      0.39        61\n",
      "\n",
      "    accuracy                           0.76       441\n",
      "   macro avg       0.61      0.67      0.62       441\n",
      "weighted avg       0.83      0.76      0.79       441\n",
      "\n",
      "AUC Test:  0.711518550474547\n",
      "True positives: 33\n",
      "True negatives: 304\n",
      "False positives (Type I error): 76\n",
      "False negatives (Type II error): 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB Scaled</td>\n",
       "      <td>104</td>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0  NB Scaled                 104            76             28       0.3   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.54           0.78          0.76     0.39    0.71  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB=GaussianNB()\n",
    "NB.fit(xtrains,y_train)\n",
    "y_pred = NB.predict(xtests)\n",
    "ytest_prob = NB.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,NB.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"NB Scaled \"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,NB.predict(xtrains)),2)\n",
    "\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "Naive_Bayes =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "Naive_Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged NB"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nb_Bag_var=[]\n",
    "nb_Bag_be=[]\n",
    "for val in np.arange(1,100):\n",
    "  NB=GaussianNB()\n",
    "  Bag=BaggingClassifier(base_estimator=NB,n_estimators=val,random_state=0)\n",
    "  kf =KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "  score= cross_val_score(Bag, x_std, y,cv=kf, scoring='roc_auc')\n",
    "  nb_Bag_var.append(np.std(score,ddof=1))\n",
    "  nb_Bag_be.append(np.mean(1-score))\n",
    "  \n",
    "print('roc_auc :',1-np.min(nb_Bag_be))\n",
    "print('Bias error :',np.min(nb_Bag_be))\n",
    "print('Variance error :',np.min(nb_Bag_var))\n",
    "np.argmin(nb_Bag_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[311  69]\n",
      " [ 32  29]]\n",
      "\n",
      "Accuracy Train:  0.7949465500485908\n",
      "Accuracy Test: 0.7709750566893424\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86       380\n",
      "           1       0.30      0.48      0.36        61\n",
      "\n",
      "    accuracy                           0.77       441\n",
      "   macro avg       0.60      0.65      0.61       441\n",
      "weighted avg       0.82      0.77      0.79       441\n",
      "\n",
      "AUC Test:  0.7147109577221742\n",
      "True positives: 29\n",
      "True negatives: 311\n",
      "False positives (Type I error): 69\n",
      "False negatives (Type II error): 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB Scaled</td>\n",
       "      <td>101</td>\n",
       "      <td>69</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0  NB Scaled                 101            69             32       0.3   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.48           0.79          0.77     0.36    0.71  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB=GaussianNB()\n",
    "NB_Bag=BaggingClassifier(base_estimator=NB,n_estimators=35,random_state=0)\n",
    "NB_Bag.fit(xtrains,y_train)\n",
    "y_pred = NB_Bag.predict(xtests)\n",
    "ytest_prob = NB_Bag.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,NB_Bag.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"NB Scaled \"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,NB_Bag.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "NB_Bag =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "NB_Bag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost NB"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ada_bias=[]\n",
    "for val in np.arange(1,100):\n",
    "  Ada=AdaBoostClassifier(base_estimator=NB,n_estimators=val,random_state=0)\n",
    "  kfold = KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "  cv_results = cross_val_score(Ada, x_std, y,cv=kfold, scoring='roc_auc')\n",
    "  Ada_bias.append(1-np.mean(cv_results))\n",
    "  \n",
    "print('roc_auc :',1-np.min(Ada_bias))\n",
    "print('Bias error :',np.min(Ada_bias))\n",
    "np.argmin(Ada_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[304  76]\n",
      " [ 28  33]]\n",
      "\n",
      "Accuracy Train:  0.7803692905733722\n",
      "Accuracy Test: 0.764172335600907\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       380\n",
      "           1       0.30      0.54      0.39        61\n",
      "\n",
      "    accuracy                           0.76       441\n",
      "   macro avg       0.61      0.67      0.62       441\n",
      "weighted avg       0.83      0.76      0.79       441\n",
      "\n",
      "AUC Test:  0.711518550474547\n",
      "True positives: 33\n",
      "True negatives: 304\n",
      "False positives (Type I error): 76\n",
      "False negatives (Type II error): 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_Ada</td>\n",
       "      <td>104</td>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0     NB_Ada                 104            76             28       0.3   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.54           0.78          0.76     0.39    0.71  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB=GaussianNB()\n",
    "NB_Ada=AdaBoostClassifier(base_estimator=NB,n_estimators=1,random_state=0)\n",
    "NB_Ada.fit(xtrains,y_train)\n",
    "y_pred = NB_Ada.predict(xtests)\n",
    "ytest_prob = NB_Ada.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,NB_Ada.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"NB_Ada \"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,NB_Ada.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "NB_Ada =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "NB_Ada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[324  56]\n",
      " [ 35  26]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.7936507936507936\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88       380\n",
      "           1       0.32      0.43      0.36        61\n",
      "\n",
      "    accuracy                           0.79       441\n",
      "   macro avg       0.61      0.64      0.62       441\n",
      "weighted avg       0.82      0.79      0.81       441\n",
      "\n",
      "AUC Test:  0.6394305435720448\n"
     ]
    }
   ],
   "source": [
    "dt_model=DecisionTreeClassifier(random_state=0) #Fully Grown DT\n",
    "#Fully grown Decision Tree\n",
    "dt_model.fit(xtrains,y_train)\n",
    "y_pred = dt_model.predict(xtests)\n",
    "ytest_prob = dt_model.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,dt_model.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 19}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform Grid Search Method to find the optimal max_depth size\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameter={'max_depth':np.arange(1,10),'criterion' : ['entropy','gini'],'min_samples_leaf':np.arange(3,20)}\n",
    "kf=KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "GS=GridSearchCV(dt_model,parameter,cv=kf,scoring='roc_auc')\n",
    "GS.fit(x_std,y)\n",
    "GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[363  17]\n",
      " [ 44  17]]\n",
      "\n",
      "Accuracy Train:  0.8668610301263362\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       380\n",
      "           1       0.50      0.28      0.36        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.70      0.62      0.64       441\n",
      "weighted avg       0.84      0.86      0.84       441\n",
      "\n",
      "AUC Test:  0.7260569456427955\n"
     ]
    }
   ],
   "source": [
    "dt_reg=DecisionTreeClassifier(max_depth=4,criterion='entropy',min_samples_leaf=19,random_state=0)##Regularised\n",
    "#Regularised Decision Tree\n",
    "dt_reg.fit(xtrains,y_train)\n",
    "y_pred = dt_reg.predict(xtests)\n",
    "ytest_prob = dt_reg.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,dt_reg.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[324  56]\n",
      " [ 35  26]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.7936507936507936\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88       380\n",
      "           1       0.32      0.43      0.36        61\n",
      "\n",
      "    accuracy                           0.79       441\n",
      "   macro avg       0.61      0.64      0.62       441\n",
      "weighted avg       0.82      0.79      0.81       441\n",
      "\n",
      "AUC Test:  0.6394305435720448\n",
      "True positives: 26\n",
      "True negatives: 324\n",
      "False positives (Type I error): 56\n",
      "False negatives (Type II error): 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>91</td>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0          DT                 91            56             35      0.32   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.43           0.79          0.79     0.36    0.64  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model=DecisionTreeClassifier(random_state=0) #Fully Grown DT\n",
    "#Fully grown Decision Tree\n",
    "dt_model.fit(xtrains,y_train)\n",
    "y_pred = dt_model.predict(xtests)\n",
    "ytest_prob = dt_model.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,dt_model.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"DT\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_test,y_pred),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "DT =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "DT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[363  17]\n",
      " [ 44  17]]\n",
      "\n",
      "Accuracy Train:  0.8668610301263362\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       380\n",
      "           1       0.50      0.28      0.36        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.70      0.62      0.64       441\n",
      "weighted avg       0.84      0.86      0.84       441\n",
      "\n",
      "AUC Test:  0.7260569456427955\n",
      "True positives: 17\n",
      "True negatives: 363\n",
      "False positives (Type I error): 17\n",
      "False negatives (Type II error): 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT_reg</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0      DT_reg                 61            17             44       0.5   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.28           0.86          0.86     0.36    0.73  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_reg=DecisionTreeClassifier(max_depth=4,criterion='entropy',min_samples_leaf=19,random_state=0)##Regularised\n",
    "#Regularised Decision Tree\n",
    "dt_reg.fit(xtrains,y_train)\n",
    "y_pred = dt_reg.predict(xtests)\n",
    "ytest_prob = dt_reg.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,dt_reg.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"DT_reg\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_test,y_pred),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "DT_reg =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "DT_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged DT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dt_Bag_var=[]\n",
    "dt_Bag_be=[]\n",
    "for val in np.arange(1,100):\n",
    "  dt_reg=DecisionTreeClassifier(max_depth=4,criterion='entropy',random_state=0)\n",
    "  Bag=BaggingClassifier(base_estimator=dt_reg,n_estimators=val,random_state=0)\n",
    "  kf =KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "  score= cross_val_score(Bag, x_std, y,cv=kf, scoring='roc_auc')\n",
    "  dt_Bag_var.append(np.std(score,ddof=1))\n",
    "  dt_Bag_be.append(np.mean(1-score))\n",
    "  \n",
    "print('roc_auc :',1-np.min(dt_Bag_be))\n",
    "print('Bias error :',np.min(dt_Bag_be))\n",
    "print('Variance error :',np.min(dt_Bag_var))\n",
    "np.argmin(dt_Bag_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[363  17]\n",
      " [ 50  11]]\n",
      "\n",
      "Accuracy Train:  0.8649173955296404\n",
      "Accuracy Test: 0.8480725623582767\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       380\n",
      "           1       0.39      0.18      0.25        61\n",
      "\n",
      "    accuracy                           0.85       441\n",
      "   macro avg       0.64      0.57      0.58       441\n",
      "weighted avg       0.81      0.85      0.82       441\n",
      "\n",
      "AUC Test:  0.6981018119068161\n",
      "True positives: 11\n",
      "True negatives: 363\n",
      "False positives (Type I error): 17\n",
      "False negatives (Type II error): 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt_Bag</td>\n",
       "      <td>67</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0      dt_Bag                 67            17             50      0.39   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.18           0.86          0.85     0.25     0.7  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_reg=DecisionTreeClassifier(max_depth=4,criterion='entropy',min_samples_leaf=19,random_state=0)##Regularised\n",
    "#Regularised Decision Tree\n",
    "dt_Bag=BaggingClassifier(base_estimator=dt_reg,n_estimators=2,random_state=0)\n",
    "dt_Bag.fit(xtrains,y_train)\n",
    "y_pred = dt_Bag.predict(xtests)\n",
    "ytest_prob = dt_Bag.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,dt_Bag.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"dt_Bag\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,dt_Bag.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "dt_Bag =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "dt_Bag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT_Ada"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ada_bias=[]\n",
    "for val in np.arange(1,100):\n",
    "  Ada=AdaBoostClassifier(base_estimator=dt_reg,n_estimators=val,random_state=0)\n",
    "  kfold = KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "  cv_results = cross_val_score(Ada, x_std, y,cv=kfold, scoring='roc_auc')\n",
    "  Ada_bias.append(1-np.mean(cv_results))\n",
    "  \n",
    "print('roc_auc :',1-np.min(Ada_bias))\n",
    "print('Bias error :',np.min(Ada_bias))\n",
    "np.argmin(Ada_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[358  22]\n",
      " [ 43  18]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.8526077097505669\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92       380\n",
      "           1       0.45      0.30      0.36        61\n",
      "\n",
      "    accuracy                           0.85       441\n",
      "   macro avg       0.67      0.62      0.64       441\n",
      "weighted avg       0.83      0.85      0.84       441\n",
      "\n",
      "AUC Test:  0.6992666091458154\n",
      "True positives: 18\n",
      "True negatives: 358\n",
      "False positives (Type I error): 22\n",
      "False negatives (Type II error): 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt_Ada</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0      dt_Ada                 65            22             43      0.45   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0    0.3            1.0          0.85     0.36     0.7  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_reg=DecisionTreeClassifier(max_depth=4,criterion='entropy',min_samples_leaf=19,random_state=0)##Regularised\n",
    "#Regularised Decision Tree\n",
    "dt_Ada=AdaBoostClassifier(base_estimator=dt_reg,n_estimators=96,random_state=0)\n",
    "dt_Ada.fit(xtrains,y_train)\n",
    "y_pred = dt_Ada.predict(xtests)\n",
    "ytest_prob = dt_Ada.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,dt_Ada.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"dt_Ada\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,dt_Ada.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "dt_ada =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "dt_ada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[375   5]\n",
      " [ 54   7]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.8662131519274376\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       380\n",
      "           1       0.58      0.11      0.19        61\n",
      "\n",
      "    accuracy                           0.87       441\n",
      "   macro avg       0.73      0.55      0.56       441\n",
      "weighted avg       0.83      0.87      0.83       441\n",
      "\n",
      "AUC Test:  0.788481449525453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(xtrains,y_train)\n",
    "y_pred = rfc.predict(xtests)\n",
    "ytest_prob = rfc.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,rfc.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(n_estimators=20,\n",
       "                                                    random_state=0),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001948534B108>,\n",
       "                                        'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001948534B3C8>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000194852B8848>},\n",
       "                   random_state=0, scoring='roc_auc')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "rfc_tunned=RandomForestClassifier(n_estimators=20,random_state=0)\n",
    "params={'n_estimators':sp_randint(1,20),\n",
    "        'max_features':sp_randint(1,6),\n",
    "        'max_depth':sp_randint(2,10),\n",
    "        'criterion':['gini','entropy']}\n",
    "\n",
    "rsearch_rfc=RandomizedSearchCV(rfc_tunned,params,cv=3,scoring='roc_auc',n_jobs=-1,random_state=0)\n",
    "\n",
    "rsearch_rfc.fit(x_std,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 9, 'max_features': 1, 'n_estimators': 19}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsearch_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[379   1]\n",
      " [ 58   3]]\n",
      "\n",
      "Accuracy Train:  0.9193391642371235\n",
      "Accuracy Test: 0.8662131519274376\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       380\n",
      "           1       0.75      0.05      0.09        61\n",
      "\n",
      "    accuracy                           0.87       441\n",
      "   macro avg       0.81      0.52      0.51       441\n",
      "weighted avg       0.85      0.87      0.81       441\n",
      "\n",
      "AUC Test:  0.7213114754098361\n"
     ]
    }
   ],
   "source": [
    "rfc_tunned=RandomForestClassifier(**rsearch_rfc.best_params_,random_state=0)\n",
    "\n",
    "rfc_tunned.fit(xtrains,y_train)\n",
    "y_pred = rfc_tunned.predict(xtests)\n",
    "ytest_prob = rfc_tunned.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,rfc_tunned.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[375   5]\n",
      " [ 56   5]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       380\n",
      "           1       0.50      0.08      0.14        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.69      0.53      0.53       441\n",
      "weighted avg       0.82      0.86      0.82       441\n",
      "\n",
      "AUC Test:  0.7728429680759276\n",
      "True positives: 5\n",
      "True negatives: 375\n",
      "False positives (Type I error): 5\n",
      "False negatives (Type II error): 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0          RF                 61             5             56       0.5   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.08            1.0          0.86     0.14    0.77  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(xtrains,y_train)\n",
    "y_pred = rfc.predict(xtests)\n",
    "ytest_prob = rfc.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,rfc.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"RF\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,rfc.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "RF =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                    accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[379   1]\n",
      " [ 58   3]]\n",
      "\n",
      "Accuracy Train:  0.9193391642371235\n",
      "Accuracy Test: 0.8662131519274376\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       380\n",
      "           1       0.75      0.05      0.09        61\n",
      "\n",
      "    accuracy                           0.87       441\n",
      "   macro avg       0.81      0.52      0.51       441\n",
      "weighted avg       0.85      0.87      0.81       441\n",
      "\n",
      "AUC Test:  0.7213114754098361\n",
      "True positives: 3\n",
      "True negatives: 379\n",
      "False positives (Type I error): 1\n",
      "False negatives (Type II error): 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF tuned</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0    RF tuned                 59             1             58      0.75   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.05           0.92          0.87     0.09    0.72  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_tunned=RandomForestClassifier(**rsearch_rfc.best_params_,random_state=0)\n",
    "rfc_tunned.fit(xtrains,y_train)\n",
    "y_pred = rfc_tunned.predict(xtests)\n",
    "ytest_prob = rfc_tunned.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,rfc_tunned.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"RF tuned\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,rfc_tunned.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "RF_tuned =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                      accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "RF_tuned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boosting RandomForest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ada_bias=[]\n",
    "for val in np.arange(1,100):\n",
    "  Ada=AdaBoostClassifier(base_estimator=rfc_tunned,n_estimators=val,random_state=0)\n",
    "  kfold = KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "  cv_results = cross_val_score(Ada, x_std, y,cv=kfold, scoring='roc_auc')\n",
    "  Ada_bias.append(1-np.mean(cv_results))\n",
    "  \n",
    "print('roc_auc :',1-np.min(Ada_bias))\n",
    "print('Bias error :',np.min(Ada_bias))\n",
    "np.argmin(Ada_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[379   1]\n",
      " [ 59   2]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.8639455782312925\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       380\n",
      "           1       0.67      0.03      0.06        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.77      0.52      0.49       441\n",
      "weighted avg       0.84      0.86      0.81       441\n",
      "\n",
      "AUC Test:  0.695772217428818\n",
      "True positives: 2\n",
      "True negatives: 379\n",
      "False positives (Type I error): 1\n",
      "False negatives (Type II error): 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rf_Ada</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0      Rf_Ada                 60             1             59      0.67   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.03            1.0          0.86     0.06     0.7  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_Ada=AdaBoostClassifier(base_estimator=rfc_tunned,n_estimators=22,random_state=0)\n",
    "rf_Ada.fit(xtrains,y_train)\n",
    "y_pred = rf_Ada.predict(xtests)\n",
    "ytest_prob = rf_Ada.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,rf_Ada.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"Rf_Ada\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,rf_Ada.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "Rf_Ada =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                      accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "Rf_Ada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR Scaled</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bag_LR</td>\n",
       "      <td>61</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ada_LR</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GB</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN Scaled</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN Scaled hypertuned</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bag_KNN</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB Scaled</td>\n",
       "      <td>104</td>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NB Scaled</td>\n",
       "      <td>101</td>\n",
       "      <td>69</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NB_Ada</td>\n",
       "      <td>104</td>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>91</td>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dt_Bag</td>\n",
       "      <td>67</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dt_Ada</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RF</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF tuned</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rf_Ada</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Description Misclassifications Type I errors Type II errors  \\\n",
       "0               LR Scaled                 61            11             50   \n",
       "1                  Bag_LR                 61            16             45   \n",
       "2                  Ada_LR                 55             4             51   \n",
       "3                      GB                 57            15             42   \n",
       "4              KNN Scaled                 56             2             54   \n",
       "5   KNN Scaled hypertuned                 61             0             61   \n",
       "6                 Bag_KNN                 61             0             61   \n",
       "7              NB Scaled                 104            76             28   \n",
       "8              NB Scaled                 101            69             32   \n",
       "9                 NB_Ada                 104            76             28   \n",
       "10                     DT                 91            56             35   \n",
       "11                 dt_Bag                 67            17             50   \n",
       "12                 dt_Ada                 65            22             43   \n",
       "13                     RF                 61             5             56   \n",
       "14               RF tuned                 59             1             58   \n",
       "15                 Rf_Ada                 60             1             59   \n",
       "\n",
       "   Precision Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0       0.66    0.3           0.88          0.86     0.41    0.79  \n",
       "1        0.5   0.26           0.77          0.86     0.34    0.76  \n",
       "2       0.71   0.16            0.8          0.88     0.27    0.76  \n",
       "3       0.56   0.31           0.75          0.87      0.4    0.81  \n",
       "4       0.78   0.11           0.87          0.87      0.2    0.63  \n",
       "5        0.0    0.0            1.0          0.86      0.0    0.74  \n",
       "6        0.0    0.0            0.8          0.86      0.0    0.75  \n",
       "7        0.3   0.54           0.78          0.76     0.39    0.71  \n",
       "8        0.3   0.48           0.79          0.77     0.36    0.71  \n",
       "9        0.3   0.54           0.78          0.76     0.39    0.71  \n",
       "10      0.32   0.43           0.79          0.79     0.36    0.64  \n",
       "11      0.39   0.18           0.86          0.85     0.25     0.7  \n",
       "12      0.45    0.3            1.0          0.85     0.36     0.7  \n",
       "13       0.5   0.08            1.0          0.86     0.14    0.77  \n",
       "14      0.75   0.05           0.92          0.87     0.09    0.72  \n",
       "15      0.67   0.03            1.0          0.86     0.06     0.7  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results=pd.DataFrame()\n",
    "df_results=df_results.append(LR_Scaled, ignore_index=True)\n",
    "df_results=df_results.append(bag_LR, ignore_index=True)\n",
    "df_results=df_results.append(Ada_LR, ignore_index=True)\n",
    "\n",
    "df_results=df_results.append(GB, ignore_index=True)\n",
    "df_results=df_results.append(Kneighbors, ignore_index=True)\n",
    "df_results=df_results.append(knn_tuned, ignore_index=True)\n",
    "df_results=df_results.append(bag_KNN, ignore_index=True)\n",
    "df_results=df_results.append(Naive_Bayes, ignore_index=True)\n",
    "df_results=df_results.append(NB_Bag, ignore_index=True)\n",
    "df_results=df_results.append(NB_Ada, ignore_index=True)\n",
    "df_results=df_results.append(DT, ignore_index=True)\n",
    "df_results=df_results.append(dt_Bag, ignore_index=True)\n",
    "df_results=df_results.append(dt_ada, ignore_index=True)\n",
    "df_results=df_results.append(RF, ignore_index=True)\n",
    "df_results=df_results.append(RF_tuned, ignore_index=True)\n",
    "df_results=df_results.append(Rf_Ada, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
