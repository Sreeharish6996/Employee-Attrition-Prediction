{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
       "       'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount',\n",
       "       'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'HourlyRate',\n",
       "       'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction',\n",
       "       'MaritalStatus', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
       "       'Over18', 'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
       "       'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n",
       "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
       "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
       "       'YearsWithCurrManager'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "#df=df.drop(['EmployeeNumber','EmployeeCount','StandardHours','Over18'],axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binning\n",
    "df['MonthlyIncome']=pd.cut(df['MonthlyIncome'],bins=4,labels=['Very low','Low','Moderate','High'])\n",
    "#Binning\n",
    "df['Age']=pd.cut(df['Age'],bins=3,labels=['Youth','Middle Aged','Elderly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Attrition', 'BusinessTravel', 'Department', 'EducationField',\n",
       "       'Gender', 'JobRole', 'MaritalStatus', 'MonthlyIncome', 'Over18',\n",
       "       'OverTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num=df.select_dtypes(include=['int64','float'])\n",
    "df_cat=df.select_dtypes(exclude=['int64','float'])\n",
    "df_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df_cat['MonthlyIncome']=le.fit_transform(df['MonthlyIncome'])\n",
    "df_cat['Age']=le.fit_transform(df['Age'])\n",
    "df_cat['BusinessTravel']=le.fit_transform(df['BusinessTravel'])\n",
    "df_cat['Department']=le.fit_transform(df['Department'])\n",
    "df_cat['EducationField']=le.fit_transform(df['EducationField'])\n",
    "df_cat['Gender']=le.fit_transform(df['Gender'])\n",
    "df_cat['JobRole']=le.fit_transform(df['JobRole'])\n",
    "df_cat['MaritalStatus']=le.fit_transform(df['MaritalStatus'])\n",
    "df_cat['OverTime']=le.fit_transform(df['OverTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.concat([df_num,df_cat],axis=1)\n",
    "df1=df1.drop(['EmployeeCount','StandardHours','Over18'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>Gender</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>OverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1102</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19479</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24907</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2396</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1392</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23159</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16632</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DailyRate  DistanceFromHome  Education  EmployeeNumber  \\\n",
       "0       1102                 1          2               1   \n",
       "1        279                 8          1               2   \n",
       "2       1373                 2          2               4   \n",
       "3       1392                 3          4               5   \n",
       "4        591                 2          1               7   \n",
       "\n",
       "   EnvironmentSatisfaction  HourlyRate  JobInvolvement  JobLevel  \\\n",
       "0                        2          94               3         2   \n",
       "1                        3          61               2         2   \n",
       "2                        4          92               2         1   \n",
       "3                        4          56               3         1   \n",
       "4                        1          40               3         1   \n",
       "\n",
       "   JobSatisfaction  MonthlyRate  ...  Age  Attrition  BusinessTravel  \\\n",
       "0                4        19479  ...    1        Yes               2   \n",
       "1                2        24907  ...    0         No               1   \n",
       "2                3         2396  ...    1        Yes               2   \n",
       "3                3        23159  ...    1         No               1   \n",
       "4                2        16632  ...    2         No               2   \n",
       "\n",
       "   Department  EducationField  Gender  JobRole  MaritalStatus  MonthlyIncome  \\\n",
       "0           2               1       0        7              2              1   \n",
       "1           1               1       1        6              1              3   \n",
       "2           1               4       1        2              2              3   \n",
       "3           1               1       0        6              1              3   \n",
       "4           1               3       1        2              1              3   \n",
       "\n",
       "   OverTime  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Attrition']=df1['Attrition'].replace({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Scale the input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x=df1.drop('Attrition',axis=1)\n",
    "y=df1['Attrition']\n",
    "x_scaler=StandardScaler()\n",
    "x_std=x_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[358   8]\n",
      " [ 45  30]]\n",
      "\n",
      "Accuracy Train:  0.8736637512147716\n",
      "Accuracy Test: 0.8798185941043084\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93       366\n",
      "           1       0.79      0.40      0.53        75\n",
      "\n",
      "    accuracy                           0.88       441\n",
      "   macro avg       0.84      0.69      0.73       441\n",
      "weighted avg       0.87      0.88      0.86       441\n",
      "\n",
      "AUC Test:  0.8091074681238616\n",
      "True positives: 30\n",
      "True negatives: 358\n",
      "False positives (Type I error): 8\n",
      "False negatives (Type II error): 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR Scaled</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0   LR Scaled                 53             8             45      0.79   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0    0.4           0.87          0.88     0.53    0.81  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report, roc_auc_score,roc_curve,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_std,y,test_size=0.3,random_state=3)\n",
    "\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "ytest_prob = lr.predict_proba(X_test)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,lr.predict(X_train)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"LR Scaled\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,lr.predict(X_train)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "df_results0 =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "df_results0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR_Bag_var=[]\n",
    "LR_Bag_be=[]\n",
    "for val in np.arange(1,100):\n",
    "  lr=LogisticRegression()\n",
    "  Bag=BaggingClassifier(base_estimator=lr,n_estimators=val,random_state=0)\n",
    "\n",
    "    \n",
    "Bag.fit(X_train,y_train)\n",
    "y_pred = Bag.predict(X_test)\n",
    "ytest_prob = Bag.predict_proba(x_test)[:,1]\n",
    "\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,Bag.predict(X_train)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred)) \n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ytest_prob = Bag.predict_proba(x_test)[:,1]\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data leak\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.3)\n",
    "ss=StandardScaler()\n",
    "xtrains=ss.fit_transform(x_train)\n",
    "xtests=ss.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[364  16]\n",
      " [ 46  15]]\n",
      "\n",
      "Accuracy Train:  0.8746355685131195\n",
      "Accuracy Test: 0.8594104308390023\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       380\n",
      "           1       0.48      0.25      0.33        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.69      0.60      0.62       441\n",
      "weighted avg       0.83      0.86      0.84       441\n",
      "\n",
      "AUC Test:  0.7657031924072476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve,accuracy_score\n",
    "lr1=LogisticRegression()\n",
    "lr1.fit(xtrains,y_train)\n",
    "y_pred = lr1.predict(xtests)\n",
    "ytest_prob = lr1.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,lr1.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[266 100]\n",
      " [ 36  39]]\n",
      "\n",
      "Accuracy Train:  0.7450980392156863\n",
      "Accuracy Test: 0.691609977324263\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80       366\n",
      "           1       0.28      0.52      0.36        75\n",
      "\n",
      "    accuracy                           0.69       441\n",
      "   macro avg       0.58      0.62      0.58       441\n",
      "weighted avg       0.78      0.69      0.72       441\n",
      "\n",
      "AUC Test:  0.6659744990892532\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=3)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train,y_train=sm.fit_sample(X_train,y_train)\n",
    "\n",
    "sns.countplot(y_train)\n",
    "\n",
    "lrs=LogisticRegression()\n",
    "lrs.fit(X_train,y_train)\n",
    "y_pred = lrs.predict(X_test)\n",
    "ytest_prob = lrs.predict_proba(X_test)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,lrs.predict(X_train)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE SCALED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[289  77]\n",
      " [ 25  50]]\n",
      "\n",
      "Accuracy Train:  0.7831603229527105\n",
      "Accuracy Test: 0.7687074829931972\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85       366\n",
      "           1       0.39      0.67      0.50        75\n",
      "\n",
      "    accuracy                           0.77       441\n",
      "   macro avg       0.66      0.73      0.67       441\n",
      "weighted avg       0.83      0.77      0.79       441\n",
      "\n",
      "AUC Test:  0.8069216757741348\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_std,y,test_size=0.3,random_state=3)\n",
    "\n",
    "smo = SMOTE(random_state=42)\n",
    "X_train,y_train=smo.fit_sample(X_train,y_train)\n",
    "\n",
    "sns.countplot(y_train)\n",
    "\n",
    "lrs=LogisticRegression()\n",
    "lrs.fit(X_train,y_train)\n",
    "y_pred = lrs.predict(X_test)\n",
    "ytest_prob = lrs.predict_proba(X_test)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,lrs.predict(X_train)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DailyRate', 'MonthlyRate', 'EmployeeNumber', 'OverTime',\n",
       "       'DistanceFromHome', 'TotalWorkingYears', 'HourlyRate',\n",
       "       'YearsAtCompany', 'PercentSalaryHike', 'NumCompaniesWorked',\n",
       "       'EnvironmentSatisfaction', 'JobRole', 'YearsWithCurrManager',\n",
       "       'YearsInCurrentRole', 'StockOptionLevel', 'JobLevel',\n",
       "       'JobSatisfaction', 'TrainingTimesLastYear', 'JobInvolvement',\n",
       "       'Age', 'WorkLifeBalance', 'YearsSinceLastPromotion',\n",
       "       'EducationField', 'RelationshipSatisfaction', 'MaritalStatus',\n",
       "       'Education', 'BusinessTravel', 'Department', 'Gender',\n",
       "       'MonthlyIncome', 'PerformanceRating'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Selection using Feature Importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x,y)\n",
    "rf.feature_importances_\n",
    "dfr=pd.DataFrame()\n",
    "dfr['rf']=rf.feature_importances_*100\n",
    "dfr['col']=x.columns\n",
    "dfr.sort_values(by='rf',ascending=False)['col'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[270 110]\n",
      " [ 44  17]]\n",
      "\n",
      "Accuracy Train:  0.8746355685131195\n",
      "Accuracy Test: 0.6507936507936508\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.78       380\n",
      "           1       0.13      0.28      0.18        61\n",
      "\n",
      "    accuracy                           0.65       441\n",
      "   macro avg       0.50      0.49      0.48       441\n",
      "weighted avg       0.76      0.65      0.70       441\n",
      "\n",
      "AUC Test:  0.4720448662640207\n",
      "True positives: 17\n",
      "True negatives: 270\n",
      "False positives (Type I error): 110\n",
      "False negatives (Type II error): 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR scaled selected</td>\n",
       "      <td>154</td>\n",
       "      <td>110</td>\n",
       "      <td>44</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Description Misclassifications Type I errors Type II errors  \\\n",
       "0  LR scaled selected                154           110             44   \n",
       "\n",
       "  Precision Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0      0.13   0.28           0.87          0.65     0.18    0.47  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve,accuracy_score\n",
    "x1=df1[['DailyRate', 'TotalWorkingYears', 'OverTime', 'MonthlyRate',\n",
    "       'EmployeeNumber', 'HourlyRate', 'DistanceFromHome',\n",
    "       'YearsAtCompany', 'PercentSalaryHike', 'JobRole',\n",
    "       'NumCompaniesWorked', 'YearsWithCurrManager',\n",
    "       'EnvironmentSatisfaction', 'JobSatisfaction', 'StockOptionLevel',\n",
    "       'YearsInCurrentRole', 'RelationshipSatisfaction',\n",
    "       'TrainingTimesLastYear', 'WorkLifeBalance', 'EducationField',\n",
    "       'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',\n",
    "       'JobInvolvement', 'Age', 'Education', 'BusinessTravel',\n",
    "       'Department', 'Gender', 'MonthlyIncome', 'PerformanceRating']]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x1,y,random_state=42,test_size=0.3)\n",
    "ss=StandardScaler()\n",
    "xtrains=ss.fit_transform(x_train)\n",
    "xtests=ss.fit_transform(x_test)\n",
    "lr2=LogisticRegression()\n",
    "lr2.fit(xtrains,y_train)\n",
    "y_pred1 = lr2.predict(xtests)\n",
    "ytest_prob1 = lr2.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,lr2.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"LR scaled selected\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,lr2.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "df_results1 =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "df_results1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[266 100]\n",
      " [ 36  39]]\n",
      "\n",
      "Accuracy Train:  0.7399077277970012\n",
      "Accuracy Test: 0.691609977324263\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80       366\n",
      "           1       0.28      0.52      0.36        75\n",
      "\n",
      "    accuracy                           0.69       441\n",
      "   macro avg       0.58      0.62      0.58       441\n",
      "weighted avg       0.78      0.69      0.72       441\n",
      "\n",
      "AUC Test:  0.6637158469945355\n",
      "True positives: 39\n",
      "True negatives: 266\n",
      "False positives (Type I error): 100\n",
      "False negatives (Type II error): 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR Smote selected</td>\n",
       "      <td>136</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Description Misclassifications Type I errors Type II errors  \\\n",
       "0  LR Smote selected                136           100             36   \n",
       "\n",
       "  Precision Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0      0.28   0.52           0.74          0.69     0.36    0.66  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1=df1[['DailyRate', 'TotalWorkingYears', 'OverTime', 'MonthlyRate',\n",
    "       'EmployeeNumber', 'HourlyRate', 'DistanceFromHome',\n",
    "       'YearsAtCompany', 'PercentSalaryHike', 'JobRole',\n",
    "       'NumCompaniesWorked', 'YearsWithCurrManager',\n",
    "       'EnvironmentSatisfaction', 'JobSatisfaction', 'StockOptionLevel',\n",
    "       'YearsInCurrentRole', 'RelationshipSatisfaction',\n",
    "       'TrainingTimesLastYear', 'WorkLifeBalance', 'EducationField',\n",
    "       'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',\n",
    "       'JobInvolvement', 'Age', 'Education', 'BusinessTravel',\n",
    "       'Department', 'Gender', 'MonthlyIncome', 'PerformanceRating']]\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x1,y,test_size=0.3,random_state=3)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train,y_train=sm.fit_sample(X_train,y_train)\n",
    "\n",
    "\n",
    "lrs=LogisticRegression()\n",
    "lrs.fit(X_train,y_train)\n",
    "y_pred = lrs.predict(X_test)\n",
    "ytest_prob = lrs.predict_proba(X_test)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,lrs.predict(X_train)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"LR Smote selected\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,lrs.predict(X_train)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "df_results2 =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "df_results2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE SCALED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[289  77]\n",
      " [ 25  50]]\n",
      "\n",
      "Accuracy Train:  0.7831603229527105\n",
      "Accuracy Test: 0.7687074829931972\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85       366\n",
      "           1       0.39      0.67      0.50        75\n",
      "\n",
      "    accuracy                           0.77       441\n",
      "   macro avg       0.66      0.73      0.67       441\n",
      "weighted avg       0.83      0.77      0.79       441\n",
      "\n",
      "AUC Test:  0.8069216757741348\n",
      "True positives: 50\n",
      "True negatives: 289\n",
      "False positives (Type I error): 77\n",
      "False negatives (Type II error): 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR Smote scaled selected</td>\n",
       "      <td>102</td>\n",
       "      <td>77</td>\n",
       "      <td>25</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Description Misclassifications Type I errors Type II errors  \\\n",
       "0  LR Smote scaled selected                102            77             25   \n",
       "\n",
       "  Precision Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0      0.39   0.67           0.78          0.77      0.5    0.81  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Scale the input\n",
    "x1=df1[['DailyRate', 'TotalWorkingYears', 'OverTime', 'MonthlyRate',\n",
    "       'EmployeeNumber', 'HourlyRate', 'DistanceFromHome',\n",
    "       'YearsAtCompany', 'PercentSalaryHike', 'JobRole',\n",
    "       'NumCompaniesWorked', 'YearsWithCurrManager',\n",
    "       'EnvironmentSatisfaction', 'JobSatisfaction', 'StockOptionLevel',\n",
    "       'YearsInCurrentRole', 'RelationshipSatisfaction',\n",
    "       'TrainingTimesLastYear', 'WorkLifeBalance', 'EducationField',\n",
    "       'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',\n",
    "       'JobInvolvement', 'Age', 'Education', 'BusinessTravel',\n",
    "       'Department', 'Gender', 'MonthlyIncome', 'PerformanceRating']]\n",
    "y=df1['Attrition']\n",
    "from imblearn.over_sampling import SMOTE\n",
    "x_scaler=StandardScaler()\n",
    "x_std1=x_scaler.fit_transform(x1)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_std1,y,test_size=0.3,random_state=3)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train,y_train=sm.fit_sample(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "lrs=LogisticRegression()\n",
    "lrs.fit(X_train,y_train)\n",
    "y_pred = lrs.predict(X_test)\n",
    "ytest_prob = lrs.predict_proba(X_test)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,lrs.predict(X_train)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"LR Smote scaled selected\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,lrs.predict(X_train)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "\n",
    "\n",
    "df_results3 =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "df_results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1734, 31)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install featuretools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[371   9]\n",
      " [ 53   8]]\n",
      "\n",
      "Accuracy Train:  0.8678328474246841\n",
      "Accuracy Test: 0.8594104308390023\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92       380\n",
      "           1       0.47      0.13      0.21        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.67      0.55      0.56       441\n",
      "weighted avg       0.82      0.86      0.82       441\n",
      "\n",
      "AUC Test:  0.6468938740293355\n",
      "True positives: 8\n",
      "True negatives: 371\n",
      "False positives (Type I error): 9\n",
      "False negatives (Type II error): 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Scaled</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0  KNN Scaled                 62             9             53      0.47   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.13           0.87          0.86     0.21    0.65  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Scale the input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve,accuracy_score\n",
    "x1=df1[['DailyRate', 'TotalWorkingYears', 'OverTime', 'MonthlyRate',\n",
    "       'EmployeeNumber', 'HourlyRate', 'DistanceFromHome',\n",
    "       'YearsAtCompany', 'PercentSalaryHike', 'JobRole',\n",
    "       'NumCompaniesWorked', 'YearsWithCurrManager',\n",
    "       'EnvironmentSatisfaction', 'JobSatisfaction', 'StockOptionLevel',\n",
    "       'YearsInCurrentRole', 'RelationshipSatisfaction',\n",
    "       'TrainingTimesLastYear', 'WorkLifeBalance', 'EducationField',\n",
    "       'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',\n",
    "       'JobInvolvement', 'Age', 'Education', 'BusinessTravel',\n",
    "       'Department', 'Gender', 'MonthlyIncome', 'PerformanceRating']]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x1,y,random_state=42,test_size=0.3)\n",
    "ss=StandardScaler()\n",
    "xtrains=ss.fit_transform(x_train)\n",
    "xtests=ss.fit_transform(x_test)\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(xtrains,y_train)\n",
    "y_pred = knn.predict(xtests)\n",
    "ytest_prob = knn.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,knn.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"KNN Scaled\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train=round(accuracy_score(y_train,knn.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "df_results4 =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "df_results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 60, 'weights': 'distance'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "knn=KNeighborsClassifier()\n",
    "param={'n_neighbors':np.arange(1,70),'weights':['uniform','distance']}\n",
    "kf =KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "grid=GridSearchCV(knn,param,cv=kf,scoring='roc_auc')\n",
    "grid.fit(x_std,y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[380   0]\n",
      " [ 61   0]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       380\n",
      "           1       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.43      0.50      0.46       441\n",
      "weighted avg       0.74      0.86      0.80       441\n",
      "\n",
      "AUC Test:  0.7129853321829163\n",
      "True positives: 0\n",
      "True negatives: 380\n",
      "False positives (Type I error): 0\n",
      "False negatives (Type II error): 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Scaled hypertuned</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Description Misclassifications Type I errors Type II errors  \\\n",
       "0  KNN Scaled hypertuned                 61             0             61   \n",
       "\n",
       "  Precision Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0       0.0    0.0            1.0          0.86      0.0    0.71  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Scale the input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve,accuracy_score\n",
    "x1=df1[['DailyRate', 'TotalWorkingYears', 'OverTime', 'MonthlyRate',\n",
    "       'EmployeeNumber', 'HourlyRate', 'DistanceFromHome',\n",
    "       'YearsAtCompany', 'PercentSalaryHike', 'JobRole',\n",
    "       'NumCompaniesWorked', 'YearsWithCurrManager',\n",
    "       'EnvironmentSatisfaction', 'JobSatisfaction', 'StockOptionLevel',\n",
    "       'YearsInCurrentRole', 'RelationshipSatisfaction',\n",
    "       'TrainingTimesLastYear', 'WorkLifeBalance', 'EducationField',\n",
    "       'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',\n",
    "       'JobInvolvement', 'Age', 'Education', 'BusinessTravel',\n",
    "       'Department', 'Gender', 'MonthlyIncome', 'PerformanceRating']]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x1,y,random_state=42,test_size=0.3)\n",
    "ss=StandardScaler()\n",
    "xtrains=ss.fit_transform(x_train)\n",
    "xtests=ss.fit_transform(x_test)\n",
    "knn=KNeighborsClassifier(n_neighbors= 66, weights= 'distance')\n",
    "knn.fit(xtrains,y_train)\n",
    "y_pred = knn.predict(xtests)\n",
    "ytest_prob = knn.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,knn.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"KNN Scaled hypertuned\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train=accuracy_score(y_train,knn.predict(xtrains))\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "df_results5 =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "df_results5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[306  74]\n",
      " [ 28  33]]\n",
      "\n",
      "Accuracy Train:  0.7803692905733722\n",
      "Accuracy Test: 0.7687074829931972\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86       380\n",
      "           1       0.31      0.54      0.39        61\n",
      "\n",
      "    accuracy                           0.77       441\n",
      "   macro avg       0.61      0.67      0.62       441\n",
      "weighted avg       0.83      0.77      0.79       441\n",
      "\n",
      "AUC Test:  0.7110871440897325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB=GaussianNB()\n",
    "NB.fit(xtrains,y_train)\n",
    "y_pred = NB.predict(xtests)\n",
    "ytest_prob = NB.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,NB.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[306  74]\n",
      " [ 28  33]]\n",
      "\n",
      "Accuracy Train:  0.7803692905733722\n",
      "Accuracy Test: 0.7687074829931972\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86       380\n",
      "           1       0.31      0.54      0.39        61\n",
      "\n",
      "    accuracy                           0.77       441\n",
      "   macro avg       0.61      0.67      0.62       441\n",
      "weighted avg       0.83      0.77      0.79       441\n",
      "\n",
      "AUC Test:  0.7110871440897325\n",
      "True positives: 33\n",
      "True negatives: 306\n",
      "False positives (Type I error): 74\n",
      "False negatives (Type II error): 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB Scaled</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>28</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0  NB Scaled                 102            74             28      0.31   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.54            1.0          0.77     0.39    0.71  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Scale the input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve,accuracy_score\n",
    "x1=df1[['DailyRate', 'TotalWorkingYears', 'OverTime', 'MonthlyRate',\n",
    "       'EmployeeNumber', 'HourlyRate', 'DistanceFromHome',\n",
    "       'YearsAtCompany', 'PercentSalaryHike', 'JobRole',\n",
    "       'NumCompaniesWorked', 'YearsWithCurrManager',\n",
    "       'EnvironmentSatisfaction', 'JobSatisfaction', 'StockOptionLevel',\n",
    "       'YearsInCurrentRole', 'RelationshipSatisfaction',\n",
    "       'TrainingTimesLastYear', 'WorkLifeBalance', 'EducationField',\n",
    "       'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',\n",
    "       'JobInvolvement', 'Age', 'Education', 'BusinessTravel',\n",
    "       'Department', 'Gender', 'MonthlyIncome', 'PerformanceRating']]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x1,y,random_state=42,test_size=0.3)\n",
    "ss=StandardScaler()\n",
    "xtrains=ss.fit_transform(x_train)\n",
    "xtests=ss.fit_transform(x_test)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB=GaussianNB()\n",
    "NB.fit(xtrains,y_train)\n",
    "y_pred = NB.predict(xtests)\n",
    "ytest_prob = NB.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,NB.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"NB Scaled \"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,NB.predict(xtrains),2))\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "df_results6 =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "df_results6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[313  67]\n",
      " [ 41  20]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.7551020408163265\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       380\n",
      "           1       0.23      0.33      0.27        61\n",
      "\n",
      "    accuracy                           0.76       441\n",
      "   macro avg       0.56      0.58      0.56       441\n",
      "weighted avg       0.79      0.76      0.77       441\n",
      "\n",
      "AUC Test:  0.575776531492666\n"
     ]
    }
   ],
   "source": [
    "dt_model=DecisionTreeClassifier(random_state=0) #Fully Grown DT\n",
    "#Fully grown Decision Tree\n",
    "dt_model.fit(xtrains,y_train)\n",
    "y_pred = dt_model.predict(xtests)\n",
    "ytest_prob = dt_model.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,dt_model.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 19}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform Grid Search Method to find the optimal max_depth size\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameter={'max_depth':np.arange(1,10),'criterion' : ['entropy','gini'],'min_samples_leaf':np.arange(3,20)}\n",
    "kf=KFold(shuffle=True,n_splits=3,random_state=0)\n",
    "GS=GridSearchCV(dt_model,parameter,cv=kf,scoring='roc_auc')\n",
    "GS.fit(x_std,y)\n",
    "GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[363  17]\n",
      " [ 44  17]]\n",
      "\n",
      "Accuracy Train:  0.8668610301263362\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       380\n",
      "           1       0.50      0.28      0.36        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.70      0.62      0.64       441\n",
      "weighted avg       0.84      0.86      0.84       441\n",
      "\n",
      "AUC Test:  0.717320966350302\n"
     ]
    }
   ],
   "source": [
    "dt_reg=DecisionTreeClassifier(max_depth=4,criterion='entropy',min_samples_leaf=19,random_state=0)##Regularised\n",
    "#Regularised Decision Tree\n",
    "dt_reg.fit(xtrains,y_train)\n",
    "y_pred = dt_reg.predict(xtests)\n",
    "ytest_prob = dt_reg.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,dt_reg.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[313  67]\n",
      " [ 41  20]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.7551020408163265\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       380\n",
      "           1       0.23      0.33      0.27        61\n",
      "\n",
      "    accuracy                           0.76       441\n",
      "   macro avg       0.56      0.58      0.56       441\n",
      "weighted avg       0.79      0.76      0.77       441\n",
      "\n",
      "AUC Test:  0.575776531492666\n",
      "True positives: 20\n",
      "True negatives: 313\n",
      "False positives (Type I error): 67\n",
      "False negatives (Type II error): 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>108</td>\n",
       "      <td>67</td>\n",
       "      <td>41</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0          DT                108            67             41      0.23   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.33           0.76          0.76     0.27    0.58  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale the input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve,accuracy_score\n",
    "x1=df1[['DailyRate', 'TotalWorkingYears', 'OverTime', 'MonthlyRate',\n",
    "       'EmployeeNumber', 'HourlyRate', 'DistanceFromHome',\n",
    "       'YearsAtCompany', 'PercentSalaryHike', 'JobRole',\n",
    "       'NumCompaniesWorked', 'YearsWithCurrManager',\n",
    "       'EnvironmentSatisfaction', 'JobSatisfaction', 'StockOptionLevel',\n",
    "       'YearsInCurrentRole', 'RelationshipSatisfaction',\n",
    "       'TrainingTimesLastYear', 'WorkLifeBalance', 'EducationField',\n",
    "       'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',\n",
    "       'JobInvolvement', 'Age', 'Education', 'BusinessTravel',\n",
    "       'Department', 'Gender', 'MonthlyIncome', 'PerformanceRating']]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x1,y,random_state=42,test_size=0.3)\n",
    "ss=StandardScaler()\n",
    "xtrains=ss.fit_transform(x_train)\n",
    "xtests=ss.fit_transform(x_test)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "dt_model=DecisionTreeClassifier(random_state=0) #Fully Grown DT\n",
    "#Fully grown Decision Tree\n",
    "dt_model.fit(xtrains,y_train)\n",
    "y_pred = dt_model.predict(xtests)\n",
    "ytest_prob = dt_model.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,dt_model.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"DT\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_test,y_pred),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "df_results7 =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "df_results7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[363  17]\n",
      " [ 44  17]]\n",
      "\n",
      "Accuracy Train:  0.8668610301263362\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       380\n",
      "           1       0.50      0.28      0.36        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.70      0.62      0.64       441\n",
      "weighted avg       0.84      0.86      0.84       441\n",
      "\n",
      "AUC Test:  0.717320966350302\n",
      "True positives: 17\n",
      "True negatives: 363\n",
      "False positives (Type I error): 17\n",
      "False negatives (Type II error): 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT reg</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0      DT reg                 61            17             44       0.5   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.28           0.86          0.86     0.36    0.72  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale the input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve,accuracy_score\n",
    "x1=df1[['DailyRate', 'TotalWorkingYears', 'OverTime', 'MonthlyRate',\n",
    "       'EmployeeNumber', 'HourlyRate', 'DistanceFromHome',\n",
    "       'YearsAtCompany', 'PercentSalaryHike', 'JobRole',\n",
    "       'NumCompaniesWorked', 'YearsWithCurrManager',\n",
    "       'EnvironmentSatisfaction', 'JobSatisfaction', 'StockOptionLevel',\n",
    "       'YearsInCurrentRole', 'RelationshipSatisfaction',\n",
    "       'TrainingTimesLastYear', 'WorkLifeBalance', 'EducationField',\n",
    "       'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',\n",
    "       'JobInvolvement', 'Age', 'Education', 'BusinessTravel',\n",
    "       'Department', 'Gender', 'MonthlyIncome', 'PerformanceRating']]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x1,y,random_state=42,test_size=0.3)\n",
    "ss=StandardScaler()\n",
    "xtrains=ss.fit_transform(x_train)\n",
    "xtests=ss.fit_transform(x_test)\n",
    "dt_reg=DecisionTreeClassifier(max_depth=4,criterion='entropy',min_samples_leaf=19,random_state=0)##Regularised\n",
    "#Regularised Decision Tree\n",
    "dt_reg.fit(xtrains,y_train)\n",
    "y_pred = dt_reg.predict(xtests)\n",
    "ytest_prob = dt_reg.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,dt_reg.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"DT reg\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_test,y_pred),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "df_results8 =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "df_results8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[376   4]\n",
      " [ 56   5]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.8639455782312925\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       380\n",
      "           1       0.56      0.08      0.14        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.71      0.54      0.53       441\n",
      "weighted avg       0.83      0.86      0.82       441\n",
      "\n",
      "AUC Test:  0.7752804141501295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(xtrains,y_train)\n",
    "y_pred = rfc.predict(xtests)\n",
    "ytest_prob = rfc.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,rfc.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(n_estimators=20,\n",
       "                                                    random_state=0),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000028BF76EA4C8>,\n",
       "                                        'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000028BF76925C8>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000028BF765C388>},\n",
       "                   random_state=0, scoring='roc_auc')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "rfc_tunned=RandomForestClassifier(n_estimators=20,random_state=0)\n",
    "params={'n_estimators':sp_randint(1,20),\n",
    "        'max_features':sp_randint(1,6),\n",
    "        'max_depth':sp_randint(2,10),\n",
    "        'criterion':['gini','entropy']}\n",
    "\n",
    "rsearch_rfc=RandomizedSearchCV(rfc_tunned,params,cv=3,scoring='roc_auc',n_jobs=-1,random_state=0)\n",
    "\n",
    "rsearch_rfc.fit(x_std,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'n_estimators': 18}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsearch_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[380   0]\n",
      " [ 61   0]]\n",
      "\n",
      "Accuracy Train:  0.8289601554907677\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       380\n",
      "           1       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.43      0.50      0.46       441\n",
      "weighted avg       0.74      0.86      0.80       441\n",
      "\n",
      "AUC Test:  0.7248058671268335\n"
     ]
    }
   ],
   "source": [
    "rfc_tunned=RandomForestClassifier(**rsearch_rfc.best_params_,random_state=0)\n",
    "\n",
    "rfc_tunned.fit(xtrains,y_train)\n",
    "y_pred = rfc_tunned.predict(xtests)\n",
    "ytest_prob = rfc_tunned.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,rfc_tunned.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[375   5]\n",
      " [ 56   5]]\n",
      "\n",
      "Accuracy Train:  1.0\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       380\n",
      "           1       0.50      0.08      0.14        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.69      0.53      0.53       441\n",
      "weighted avg       0.82      0.86      0.82       441\n",
      "\n",
      "AUC Test:  0.7767471958584986\n",
      "True positives: 5\n",
      "True negatives: 375\n",
      "False positives (Type I error): 5\n",
      "False negatives (Type II error): 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0          RF                 61             5             56       0.5   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0   0.08            1.0          0.86     0.14    0.53  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale the input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve,accuracy_score\n",
    "x1=df1[['DailyRate', 'TotalWorkingYears', 'OverTime', 'MonthlyRate',\n",
    "       'EmployeeNumber', 'HourlyRate', 'DistanceFromHome',\n",
    "       'YearsAtCompany', 'PercentSalaryHike', 'JobRole',\n",
    "       'NumCompaniesWorked', 'YearsWithCurrManager',\n",
    "       'EnvironmentSatisfaction', 'JobSatisfaction', 'StockOptionLevel',\n",
    "       'YearsInCurrentRole', 'RelationshipSatisfaction',\n",
    "       'TrainingTimesLastYear', 'WorkLifeBalance', 'EducationField',\n",
    "       'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',\n",
    "       'JobInvolvement', 'Age', 'Education', 'BusinessTravel',\n",
    "       'Department', 'Gender', 'MonthlyIncome', 'PerformanceRating']]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x1,y,random_state=42,test_size=0.3)\n",
    "ss=StandardScaler()\n",
    "xtrains=ss.fit_transform(x_train)\n",
    "xtests=ss.fit_transform(x_test)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(xtrains,y_train)\n",
    "y_pred = rfc.predict(xtests)\n",
    "ytest_prob = rfc.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,rfc.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"RF\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,rfc.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,y_pred),2)\n",
    "\n",
    "df_results9 =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                    accuracy_train,\n",
    "                                     accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "df_results9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion: [[380   0]\n",
      " [ 61   0]]\n",
      "\n",
      "Accuracy Train:  0.8289601554907677\n",
      "Accuracy Test: 0.8616780045351474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       380\n",
      "           1       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.43      0.50      0.46       441\n",
      "weighted avg       0.74      0.86      0.80       441\n",
      "\n",
      "AUC Test:  0.7248058671268335\n",
      "True positives: 0\n",
      "True negatives: 380\n",
      "False positives (Type I error): 0\n",
      "False negatives (Type II error): 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF tuned</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Description Misclassifications Type I errors Type II errors Precision  \\\n",
       "0    RF tuned                 61             0             61       0.0   \n",
       "\n",
       "  Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0    0.0           0.83          0.86      0.0    0.72  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale the input\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve,accuracy_score\n",
    "x1=df1[['DailyRate', 'TotalWorkingYears', 'OverTime', 'MonthlyRate',\n",
    "       'EmployeeNumber', 'HourlyRate', 'DistanceFromHome',\n",
    "       'YearsAtCompany', 'PercentSalaryHike', 'JobRole',\n",
    "       'NumCompaniesWorked', 'YearsWithCurrManager',\n",
    "       'EnvironmentSatisfaction', 'JobSatisfaction', 'StockOptionLevel',\n",
    "       'YearsInCurrentRole', 'RelationshipSatisfaction',\n",
    "       'TrainingTimesLastYear', 'WorkLifeBalance', 'EducationField',\n",
    "       'YearsSinceLastPromotion', 'JobLevel', 'MaritalStatus',\n",
    "       'JobInvolvement', 'Age', 'Education', 'BusinessTravel',\n",
    "       'Department', 'Gender', 'MonthlyIncome', 'PerformanceRating']]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x1,y,random_state=42,test_size=0.3)\n",
    "ss=StandardScaler()\n",
    "xtrains=ss.fit_transform(x_train)\n",
    "xtests=ss.fit_transform(x_test)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_tunned=RandomForestClassifier(**rsearch_rfc.best_params_,random_state=0)\n",
    "rfc_tunned.fit(xtrains,y_train)\n",
    "y_pred = rfc_tunned.predict(xtests)\n",
    "ytest_prob = rfc_tunned.predict_proba(xtests)[:,1]\n",
    "print(\"Confusion:\",confusion_matrix(y_test,y_pred))\n",
    "print()\n",
    "print(\"Accuracy Train: \",accuracy_score(y_train,rfc_tunned.predict(xtrains)))\n",
    "print(\"Accuracy Test:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC Test: \",roc_auc_score(y_test,ytest_prob))\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n",
    "\n",
    "# calculating TP,TN,FP,FN\n",
    "TN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n",
    "\n",
    "# print values\n",
    "print(\"True positives:\", TP)\n",
    "print(\"True negatives:\", TN)\n",
    "print(\"False positives (Type I error):\", FP)\n",
    "print(\"False negatives (Type II error):\", FN)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# itereation results\n",
    "description = \"RF tuned\"\n",
    "misclassifications = FP + FN\n",
    "type1 = FP\n",
    "type2 = FN\n",
    "precision = round(precision_score(y_test,y_pred),2)\n",
    "recall = round(recall_score(y_test,y_pred),2)\n",
    "accuracy_train = round(accuracy_score(y_train,rfc_tunned.predict(xtrains)),2)\n",
    "accuracy_test = round(accuracy_score(y_test,y_pred),2)\n",
    "f1 = round(f1_score(y_test,y_pred),2)\n",
    "auc = round(roc_auc_score(y_test,ytest_prob),2)\n",
    "\n",
    "df_results10 =pd.DataFrame(np.array([description,\n",
    "                                     misclassifications,\n",
    "                                     type1,\n",
    "                                     type2,\n",
    "                                     precision,\n",
    "                                     recall,\n",
    "                                     accuracy_train,\n",
    "                                      accuracy_test,\n",
    "                                     f1,\n",
    "                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy_train','Accuracy_test','F1-score','ROC AUC'])\n",
    "\n",
    "df_results10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Misclassifications</th>\n",
       "      <th>Type I errors</th>\n",
       "      <th>Type II errors</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR Scaled</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR scaled selected</td>\n",
       "      <td>154</td>\n",
       "      <td>110</td>\n",
       "      <td>44</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR Smote selected</td>\n",
       "      <td>136</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR Smote scaled selected</td>\n",
       "      <td>102</td>\n",
       "      <td>77</td>\n",
       "      <td>25</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN Scaled</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN Scaled hypertuned</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NB Scaled</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>28</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DT</td>\n",
       "      <td>108</td>\n",
       "      <td>67</td>\n",
       "      <td>41</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT reg</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF tuned</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Description Misclassifications Type I errors Type II errors  \\\n",
       "0                  LR Scaled                 53             8             45   \n",
       "1         LR scaled selected                154           110             44   \n",
       "2          LR Smote selected                136           100             36   \n",
       "3   LR Smote scaled selected                102            77             25   \n",
       "4                 KNN Scaled                 62             9             53   \n",
       "5      KNN Scaled hypertuned                 61             0             61   \n",
       "6                 NB Scaled                 102            74             28   \n",
       "7                         DT                108            67             41   \n",
       "8                     DT reg                 61            17             44   \n",
       "9                         RF                 61             5             56   \n",
       "10                  RF tuned                 61             0             61   \n",
       "\n",
       "   Precision Recall Accuracy_train Accuracy_test F1-score ROC AUC  \n",
       "0       0.79    0.4           0.87          0.88     0.53    0.81  \n",
       "1       0.13   0.28           0.87          0.65     0.18    0.47  \n",
       "2       0.28   0.52           0.74          0.69     0.36    0.66  \n",
       "3       0.39   0.67           0.78          0.77      0.5    0.81  \n",
       "4       0.47   0.13           0.87          0.86     0.21    0.65  \n",
       "5        0.0    0.0            1.0          0.86      0.0    0.71  \n",
       "6       0.31   0.54            1.0          0.77     0.39    0.71  \n",
       "7       0.23   0.33           0.76          0.76     0.27    0.58  \n",
       "8        0.5   0.28           0.86          0.86     0.36    0.72  \n",
       "9        0.5   0.08            1.0          0.86     0.14    0.53  \n",
       "10       0.0    0.0           0.83          0.86      0.0    0.72  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results=pd.DataFrame()\n",
    "df_results=df_results.append(df_results0, ignore_index=True)\n",
    "df_results=df_results.append(df_results1, ignore_index=True)\n",
    "df_results=df_results.append(df_results2, ignore_index=True)\n",
    "df_results=df_results.append(df_results3, ignore_index=True)\n",
    "df_results=df_results.append(df_results4, ignore_index=True)\n",
    "df_results=df_results.append(df_results5, ignore_index=True)\n",
    "df_results=df_results.append(df_results6, ignore_index=True)\n",
    "df_results=df_results.append(df_results7, ignore_index=True)\n",
    "df_results=df_results.append(df_results8, ignore_index=True)\n",
    "df_results=df_results.append(df_results9, ignore_index=True)\n",
    "df_results=df_results.append(df_results10, ignore_index=True)\n",
    "\n",
    "\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
